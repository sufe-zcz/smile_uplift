{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklift.metrics import qini_auc_score, uplift_auc_score\n",
    "from causalml.dataset import make_uplift_classification_logistic\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SampleComparisonNet(nn.Module):\n",
    "    def __init__(self, input_dim, shared_hidden=128, embedding_dim=64):\n",
    "        super(SampleComparisonNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features=input_dim, out_features=shared_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=shared_hidden, out_features=shared_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=shared_hidden, out_features=embedding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=embedding_dim, out_features=shared_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=shared_hidden, out_features=shared_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=shared_hidden, out_features=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        encoded = self.encoder(inputs)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "    def get_embeddings(self, inputs):\n",
    "        # Return embeddings. No gradient needed.\n",
    "        with torch.no_grad():\n",
    "            embeddings = self.encoder(inputs)\n",
    "        return embeddings\n",
    "\n",
    "    def compute_similarity(self, embeddings, tags, top_k=5):\n",
    "        # For each sample, get topK indices of other-group samples by cosine similarity.\n",
    "        normalized_embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "        cosine_similarity = torch.matmul(normalized_embeddings, normalized_embeddings.T)\n",
    "        tag = tags.float().view(-1, 1)\n",
    "        mask = (tag != tag.t())\n",
    "        masked_similarity = cosine_similarity.masked_fill(~mask, float('-inf'))\n",
    "        _, topk_indices = torch.topk(masked_similarity, k=top_k, dim=1)\n",
    "        return topk_indices\n",
    "\n",
    "    def generate_comparison_labels(self, labels, topk_indices, tags, top_k=5):\n",
    "        # For each sample, generate uplift label by group.\n",
    "        label_vector = torch.squeeze(labels, dim=1)\n",
    "        tags_vector = torch.squeeze(tags, dim=1)\n",
    "        topk_labels = label_vector[topk_indices]              # [N, top_k]\n",
    "        matched_y = topk_labels.float().mean(dim=1)           # [N]\n",
    "        uplift_label = torch.where(\n",
    "            tags_vector > 0,\n",
    "            label_vector - matched_y,                         # Treatment: Y(1) - matched_Y(0)\n",
    "            matched_y - label_vector                          # Control: matched_Y(1) - Y(0)\n",
    "        )\n",
    "        return uplift_label.unsqueeze(1)\n",
    "\n",
    "    def compute_loss(self, predictions, comparison_labels, tags):\n",
    "        assert predictions.shape == comparison_labels.shape\n",
    "        loss = F.mse_loss(predictions, comparison_labels, reduction='mean')\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=15, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_seed(seed):\n",
    "    # Set all random seeds for reproducibility.\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SampleComparisonNetModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim,\n",
    "        shared_hidden=64,\n",
    "        embedding_dim=16,\n",
    "        epochs=5,\n",
    "        patience=1,\n",
    "        batch_size=2048,\n",
    "        learning_rate=1e-4,\n",
    "        data_loader_num_workers=10,\n",
    "        random_seed=30,\n",
    "        scheduler_patience=2,\n",
    "        scheduler_factor=0.5,\n",
    "        scheduler_min_lr=1e-7,\n",
    "        top_k=5,\n",
    "    ):\n",
    "        set_seed(random_seed)\n",
    "        self.model = SampleComparisonNet(input_dim, shared_hidden, embedding_dim).to(device)\n",
    "        self.epochs = epochs\n",
    "        self.patience = patience\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = data_loader_num_workers\n",
    "        self.top_k = top_k\n",
    "        self.optim = torch.optim.AdamW(self.model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "        self.train_dataloader = None\n",
    "        self.valid_dataloader = None\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optim,\n",
    "            mode='min',\n",
    "            patience=scheduler_patience,\n",
    "            factor=scheduler_factor,\n",
    "            min_lr=scheduler_min_lr,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    def create_dataloaders(self, x, y, tags, valid_perc=None):\n",
    "        # Split/train-validation loader.\n",
    "        if valid_perc:\n",
    "            x_train, x_test, y_train, y_test, tags_train, tags_test = train_test_split(\n",
    "                x, y, tags, test_size=valid_perc, random_state=42\n",
    "            )\n",
    "            x_train = torch.Tensor(x_train)\n",
    "            x_test = torch.Tensor(x_test)\n",
    "            y_train = torch.Tensor(y_train).reshape(-1, 1)\n",
    "            y_test = torch.Tensor(y_test).reshape(-1, 1)\n",
    "            tags_train = torch.Tensor(tags_train).reshape(-1, 1)\n",
    "            tags_test = torch.Tensor(tags_test).reshape(-1, 1)\n",
    "            train_dataset = TensorDataset(x_train, y_train, tags_train)\n",
    "            valid_dataset = TensorDataset(x_test, y_test, tags_test)\n",
    "            self.train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "            self.valid_dataloader = DataLoader(valid_dataset, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "        else:\n",
    "            x = torch.Tensor(x)\n",
    "            y = torch.Tensor(y).reshape(-1, 1)\n",
    "            tags = torch.Tensor(tags).reshape(-1, 1)\n",
    "            train_dataset = TensorDataset(x, y, tags)\n",
    "            self.train_dataloader = DataLoader(\n",
    "                train_dataset, batch_size=self.batch_size, num_workers=self.num_workers\n",
    "            )\n",
    "\n",
    "    def fit(self, x, y, tags, valid_perc=None):\n",
    "        self.create_dataloaders(x, y, tags, valid_perc)\n",
    "        early_stopper = EarlyStopper(patience=self.patience, min_delta=0)\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss_sum = 0.0\n",
    "            num_batches = 0\n",
    "            for batch, (X, y_batch, tags_batch) in enumerate(self.train_dataloader):\n",
    "                self.model.train()\n",
    "                X, y_batch, tags_batch = X.to(device), y_batch.to(device), tags_batch.to(device)\n",
    "                embeddings = self.model.get_embeddings(X)\n",
    "                topk_indices = self.model.compute_similarity(embeddings, tags_batch, top_k=self.top_k)\n",
    "                comparison_labels = self.model.generate_comparison_labels(y_batch, topk_indices, tags_batch, top_k=self.top_k)\n",
    "                predictions = self.model(X)\n",
    "                loss = self.model.compute_loss(predictions, comparison_labels, tags_batch)\n",
    "                self.optim.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "                train_loss_sum += loss.item()\n",
    "                num_batches += 1\n",
    "            train_loss_mean = train_loss_sum / num_batches\n",
    "\n",
    "            if self.valid_dataloader:\n",
    "                self.model.eval()\n",
    "                valid_loss = self.validate_step()\n",
    "                print(f\"epoch: {epoch} | train_loss: {train_loss_mean:.8f} | valid_loss: {valid_loss:.8f} | lr: {self.optim.param_groups[0]['lr']:.2e}\")\n",
    "                self.scheduler.step(valid_loss)\n",
    "                if early_stopper.early_stop(valid_loss):\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"epoch: {epoch} | train_loss: {train_loss_mean:.8f} | lr: {self.optim.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "    def validate_step(self):\n",
    "        valid_loss_sum = 0.0\n",
    "        num_batches = 0\n",
    "        with torch.no_grad():\n",
    "            for batch, (X, y_batch, tags_batch) in enumerate(self.valid_dataloader):\n",
    "                embeddings = self.model.get_embeddings(X.to(device))\n",
    "                topk_indices = self.model.compute_similarity(embeddings, tags_batch.to(device), top_k=self.top_k)\n",
    "                comparison_labels = self.model.generate_comparison_labels(y_batch.to(device), topk_indices, tags_batch.to(device), top_k=self.top_k)\n",
    "                predictions = self.model(X.to(device))\n",
    "                loss = self.model.compute_loss(predictions, comparison_labels, tags_batch.to(device))\n",
    "                valid_loss_sum += loss.item()\n",
    "                num_batches += 1\n",
    "        return valid_loss_sum / num_batches\n",
    "\n",
    "    def predict(self, x, batch_size=1024):\n",
    "        # Batch prediction on test set.\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(x), batch_size):\n",
    "                x_batch = torch.Tensor(x[i:i+batch_size]).to(device)\n",
    "                pred = self.model(x_batch)\n",
    "                preds.append(pred.cpu())\n",
    "        return torch.cat(preds, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"synthetic_uplift_data.csv\")\n",
    "x_names = ['x1_informative', 'x2_informative', 'x3_informative', 'x4_informative', 'x5_informative', 'x6_informative', 'x7_informative', 'x8_informative', 'x9_informative', 'x10_informative', 'x11_redundant_linear_x9_x6_x7_x3_x5_x1_x4_x8', 'x12_redundant_linear_x7_x1_x3_x9_x5_x4_x8_x10', 'x13_redundant_linear_x8_x7_x2_x9_x3_x1_x5_x10', 'x14_redundant_linear_x4_x2_x9_x5', 'x15_redundant_linear_x1_x3_x10_x2_x4_x7_x5_x8_x9', 'x16_redundant_linear_x7_x6', 'x17_redundant_linear_x1', 'x18_redundant_linear_x2_x5_x7_x3_x1_x10_x9', 'x19_redundant_linear_x8_x6_x10_x3', 'x20_redundant_linear_x4_x7_x5_x10_x6_x9_x2', 'x21_redundant_linear_x7', 'x22_redundant_linear_x3_x10_x7', 'x23_redundant_linear_x2_x1_x10_x4_x5_x3_x8_x9_x7_x6', 'x24_redundant_linear_x8_x1', 'x25_redundant_linear_x7_x2_x1_x5_x6', 'x26_redundant_linear_x5_x3_x9_x6_x4_x8_x7_x10_x1_x2', 'x27_redundant_linear_x3_x1_x5', 'x28_redundant_linear_x6_x2_x1_x5_x3_x8_x4_x9', 'x29_redundant_linear_x10_x3', 'x30_redundant_linear_x7_x1_x10_x5_x6', 'x31_redundant_linear_x3_x6_x7', 'x32_redundant_linear_x1_x3_x10_x4_x7', 'x33_redundant_linear_x5_x4_x10_x9_x7_x3_x1_x2', 'x34_redundant_linear_x6_x7_x3_x4_x8_x2_x10_x9_x5_x1', 'x35_redundant_linear_x2_x1_x5_x6_x10_x9_x8_x7_x4_x3', 'x36_redundant_linear_x1_x2_x8_x7_x3_x9_x6_x4_x5_x10', 'x37_redundant_linear_x4_x2_x6_x3_x5_x9_x7_x10', 'x38_redundant_linear_x2_x10_x3_x1_x9', 'x39_redundant_linear_x5', 'x40_redundant_linear_x3_x10_x2_x6_x1_x5', 'x41_redundant_linear_x7_x4_x10_x2_x3_x9', 'x42_redundant_linear_x10_x2_x9', 'x43_redundant_linear_x6_x5_x1_x10_x9_x8_x2_x3', 'x44_redundant_linear_x7_x3_x5_x10_x1_x2_x6_x4_x9_x8', 'x45_redundant_linear_x3_x7_x2_x9_x6', 'x46_redundant_linear_x5_x3_x1_x9_x4', 'x47_redundant_linear_x6_x10_x9_x8_x1_x4_x3_x2_x7_x5', 'x48_redundant_linear_x7', 'x49_redundant_linear_x2_x9_x10', 'x50_redundant_linear_x5_x6_x9_x8_x7_x10_x1_x2_x3_x4', 'x51_redundant_linear_x4_x2', 'x52_redundant_linear_x8_x4_x9_x7_x2_x10', 'x53_redundant_linear_x8_x9_x3_x5_x1_x7_x6_x4_x10', 'x54_redundant_linear_x4_x5_x8_x7_x10_x1_x2_x3_x9_x6', 'x55_redundant_linear_x7_x8_x5_x2_x9_x1_x6', 'x56_redundant_linear_x5_x10_x8_x9_x1', 'x57_redundant_linear_x8', 'x58_redundant_linear_x10_x9_x2_x8_x4_x3_x6_x7_x5_x1', 'x59_redundant_linear_x2_x7_x1_x9_x3_x6_x8_x5_x4', 'x60_redundant_linear_x6_x9_x5_x3_x2_x8_x1_x10', 'x61_redundant_linear_x10_x7_x3_x8_x9_x2', 'x62_redundant_linear_x7_x1_x2_x10_x9_x8_x4_x3_x6', 'x63_redundant_linear_x3_x5_x6_x4_x2', 'x64_redundant_linear_x4_x6_x5', 'x65_redundant_linear_x5', 'x66_redundant_linear_x1_x5', 'x67_redundant_linear_x8_x10_x5_x2_x1_x3_x7_x9_x4', 'x68_redundant_linear_x4_x3_x8', 'x69_redundant_linear_x4_x3', 'x70_redundant_linear_x7_x6_x9_x8_x2_x1_x3_x10_x5_x4', 'x71_redundant_linear_x8_x7', 'x72_redundant_linear_x5_x1_x9', 'x73_redundant_linear_x2_x8_x1_x9', 'x74_redundant_linear_x7_x9_x10', 'x75_redundant_linear_x3_x10', 'x76_redundant_linear_x9_x7_x5', 'x77_redundant_linear_x1_x5_x2_x7_x6', 'x78_redundant_linear_x5_x10_x4_x6', 'x79_redundant_linear_x3_x2_x5_x8', 'x80_redundant_linear_x4_x3_x9_x10_x8_x5_x6_x2_x7_x1', 'x81_repeated_x10', 'x82_repeated_x8', 'x83_repeated_x6', 'x84_repeated_x1', 'x85_repeated_x7', 'x86_repeated_x5', 'x87_repeated_x3', 'x88_repeated_x6', 'x89_repeated_x1', 'x90_repeated_x1', 'x91_repeated_x5', 'x92_repeated_x7', 'x93_repeated_x9', 'x94_repeated_x5', 'x95_repeated_x3', 'x96_repeated_x9', 'x97_repeated_x4', 'x98_repeated_x5', 'x99_repeated_x8', 'x100_repeated_x5', 'x101_repeated_x6', 'x102_repeated_x9', 'x103_repeated_x2', 'x104_repeated_x7', 'x105_repeated_x2', 'x106_repeated_x3', 'x107_repeated_x6', 'x108_repeated_x2', 'x109_repeated_x6', 'x110_repeated_x6', 'x111_repeated_x4', 'x112_repeated_x6', 'x113_repeated_x3', 'x114_repeated_x6', 'x115_repeated_x7', 'x116_repeated_x7', 'x117_repeated_x2', 'x118_repeated_x4', 'x119_repeated_x9', 'x120_repeated_x7', 'x121_repeated_x7', 'x122_repeated_x8', 'x123_repeated_x2', 'x124_repeated_x8', 'x125_repeated_x4', 'x126_repeated_x2', 'x127_repeated_x5', 'x128_repeated_x1', 'x129_repeated_x1', 'x130_repeated_x10', 'x131_irrelevant', 'x132_irrelevant', 'x133_irrelevant', 'x134_irrelevant', 'x135_irrelevant', 'x136_irrelevant', 'x137_irrelevant', 'x138_irrelevant', 'x139_irrelevant', 'x140_irrelevant', 'x141_irrelevant', 'x142_irrelevant', 'x143_irrelevant', 'x144_irrelevant', 'x145_irrelevant', 'x146_irrelevant', 'x147_irrelevant', 'x148_irrelevant', 'x149_irrelevant', 'x150_irrelevant', 'x151_uplift', 'x152_uplift', 'x153_uplift', 'x154_uplift', 'x155_uplift', 'x156_uplift', 'x157_uplift', 'x158_uplift', 'x159_uplift', 'x160_uplift', 'x161_uplift', 'x162_uplift', 'x163_uplift', 'x164_uplift', 'x165_uplift', 'x166_uplift', 'x167_uplift', 'x168_uplift', 'x169_uplift', 'x170_uplift', 'x171_uplift', 'x172_uplift', 'x173_uplift', 'x174_uplift', 'x175_uplift', 'x176_uplift', 'x177_uplift', 'x178_uplift', 'x179_uplift', 'x180_uplift', 'x181_uplift', 'x182_uplift', 'x183_uplift', 'x184_uplift', 'x185_uplift', 'x186_uplift', 'x187_uplift', 'x188_uplift', 'x189_uplift', 'x190_uplift', 'x191_uplift', 'x192_uplift', 'x193_uplift', 'x194_uplift', 'x195_uplift', 'x196_uplift', 'x197_uplift', 'x198_uplift', 'x199_uplift', 'x200_uplift', 'x201_uplift', 'x202_uplift', 'x203_uplift', 'x204_uplift', 'x205_uplift', 'x206_uplift', 'x207_uplift', 'x208_uplift', 'x209_uplift', 'x210_uplift', 'x211_uplift', 'x212_uplift', 'x213_uplift', 'x214_uplift', 'x215_uplift', 'x216_uplift', 'x217_uplift', 'x218_uplift', 'x219_uplift', 'x220_uplift', 'x221_uplift', 'x222_uplift', 'x223_uplift', 'x224_uplift', 'x225_uplift', 'x226_uplift', 'x227_uplift', 'x228_uplift', 'x229_uplift', 'x230_uplift', 'x231_mix', 'x232_mix', 'x233_mix', 'x234_mix', 'x235_mix', 'x236_mix', 'x237_mix', 'x238_mix', 'x239_mix', 'x240_mix', 'x241_mix', 'x242_mix', 'x243_mix', 'x244_mix', 'x245_mix', 'x246_mix', 'x247_mix', 'x248_mix', 'x249_mix', 'x250_mix', 'x251_mix', 'x252_mix', 'x253_mix', 'x254_mix', 'x255_mix', 'x256_mix', 'x257_mix', 'x258_mix', 'x259_mix', 'x260_mix', 'x261_mix', 'x262_mix', 'x263_mix', 'x264_mix', 'x265_mix', 'x266_mix', 'x267_mix', 'x268_mix', 'x269_mix', 'x270_mix', 'x271_mix', 'x272_mix', 'x273_mix', 'x274_mix', 'x275_mix', 'x276_mix', 'x277_mix', 'x278_mix', 'x279_mix', 'x280_mix', 'x281_mix', 'x282_mix', 'x283_mix', 'x284_mix', 'x285_mix', 'x286_mix', 'x287_mix', 'x288_mix', 'x289_mix', 'x290_mix', 'x291_mix', 'x292_mix', 'x293_mix', 'x294_mix', 'x295_mix', 'x296_mix', 'x297_mix', 'x298_mix', 'x299_mix', 'x300_mix']\n",
    "\n",
    "df['treatment'] = (df['treatment_group_key'] == 'treatment').astype(int)\n",
    "df['true_uplift'] = df['treatment_true_effect']\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "in_features = x_names\n",
    "label_feature = 'outcome'\n",
    "treatment_feature = 'treatment'\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_df[in_features])\n",
    "X_test = scaler.transform(test_df[in_features])\n",
    "y_train = train_df[label_feature].values\n",
    "y_test = test_df[label_feature].values\n",
    "tags_train = train_df[treatment_feature].values\n",
    "tags_test = test_df[treatment_feature].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 | train_loss: 0.10495055 | valid_loss: 0.09927499 | lr: 5.00e-04\n",
      "epoch: 1 | train_loss: 0.09920587 | valid_loss: 0.10008876 | lr: 5.00e-04\n",
      "epoch: 2 | train_loss: 0.10041006 | valid_loss: 0.09995381 | lr: 5.00e-04\n",
      "epoch: 3 | train_loss: 0.10084260 | valid_loss: 0.09786592 | lr: 5.00e-04\n",
      "epoch: 4 | train_loss: 0.09915914 | valid_loss: 0.09592140 | lr: 5.00e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==== Model Training & Evaluation ====\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "model = SampleComparisonNetModel(\n",
    "    input_dim=X_train.shape[1],\n",
    "    shared_hidden=512,\n",
    "    embedding_dim=32,\n",
    "    random_seed=seed,\n",
    "    batch_size=20000,\n",
    "    learning_rate=5e-4,\n",
    "    epochs=40,\n",
    "    patience=10,\n",
    "    scheduler_patience=5,\n",
    "    scheduler_factor=0.5,\n",
    "    scheduler_min_lr=1e-10,\n",
    "    top_k=8\n",
    ")\n",
    "model.fit(X_train, y_train, tags_train, valid_perc=0.1)\n",
    "pred = model.predict(X_test).cpu().detach().numpy().reshape(-1)\n",
    "\n",
    "analysis_df = pd.DataFrame({\n",
    "    'treatment': test_df['treatment'].values,\n",
    "    'label': test_df['outcome'].values,\n",
    "    'uplift_pred': pred,\n",
    "    'true_uplift': test_df['true_uplift'].values\n",
    "})\n",
    "\n",
    "y_true = analysis_df['label'].values\n",
    "treatment = analysis_df['treatment'].values\n",
    "uplift_score = analysis_df['uplift_pred'].values\n",
    "true_uplift = analysis_df['true_uplift'].values\n",
    "\n",
    "auuc = uplift_auc_score(y_true, uplift_score, treatment)\n",
    "qini = qini_auc_score(y_true, uplift_score, treatment)\n",
    "sqrt_pehe = np.sqrt(np.mean((uplift_score - true_uplift) ** 2))\n",
    "pred_ate = np.mean(uplift_score)\n",
    "true_ate = np.mean(true_uplift)\n",
    "e_ate = np.abs(pred_ate - true_ate)\n",
    "print(f\"\\n==== Results ====\")\n",
    "print(f\"Seed {seed} | AUUC={auuc:.6f} | Qini={qini:.6f} | sqrt_PEHE={sqrt_pehe:.6f} | Îµ_ATE={e_ate:.6f}\")\n",
    "\n",
    "# ==== Optional: Distribution plot ====\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.kdeplot(true_uplift, fill=True, label='True Uplift', color='g')\n",
    "sns.kdeplot(uplift_score, fill=True, label='Model Pseudo Uplift', color='orange')\n",
    "plt.xlabel(\"Uplift\")\n",
    "plt.title(\"True vs Model Pseudo Uplift Distribution\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "causalml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
